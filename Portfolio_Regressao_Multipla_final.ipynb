{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWm6KSvV231fTqxpx9q5Wp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexKitano/Portfolio/blob/main/Portfolio_Regressao_Multipla_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19IAOxC9Xepr"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql.functions import monotonically_increasing_id, lit, col # Import necessary functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SparkSession"
      ],
      "metadata": {
        "id": "NCTxlCz-Xy72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        ".master(\"local[*]\")\\\n",
        ".appName(\"Regressão com Spark\")\\\n",
        ".getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "lau4pUTSX4XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento dos dados"
      ],
      "metadata": {
        "id": "aBmgW7H_cPDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados = spark.read.csv(\"/content/df_test.csv\", header = True)"
      ],
      "metadata": {
        "id": "Cnh4zRObeCPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados.show(truncate = False)"
      ],
      "metadata": {
        "id": "1Hz96dEKkSdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar coluna ID\n",
        "\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "dados = dados.withColumn(\"ID\", monotonically_increasing_id())\n",
        "\n",
        "dados.show(truncate = False)"
      ],
      "metadata": {
        "id": "MHnHcdvLH9_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleção de Features"
      ],
      "metadata": {
        "id": "oGNW4DbCSXsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dados\\\n",
        ".select(\"ID\", \"bedrooms\", \"grade\", \"has_basement\", \"living_in_m2\", \"renovated\", \"nice_view\", \"perfect_condition\", \"real_bathrooms\", \"has_lavatory\", \"single_floor\", \"month\", \"quartile_zone\", \"price\")\\\n",
        ".drop(\"date\")"
      ],
      "metadata": {
        "id": "a11SQfb3Saxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.show()"
      ],
      "metadata": {
        "id": "LekW_QndYacO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.count()"
      ],
      "metadata": {
        "id": "BWqAK-tmCHi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tratamento de Dados"
      ],
      "metadata": {
        "id": "RqcSmHgIn1Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.printSchema()"
      ],
      "metadata": {
        "id": "pLPqKvuvpIAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType, DoubleType, LongType, BooleanType"
      ],
      "metadata": {
        "id": "3OK4CuSHprD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        "  .withColumn('grade', dataset['grade'].cast(IntegerType()))\\\n",
        "  .withColumn('bedrooms', dataset['bedrooms'].cast(IntegerType()))\\\n",
        "  .withColumn('has_basement', dataset['has_basement'].cast(BooleanType()))\\\n",
        "  .withColumn('living_in_m2', dataset['living_in_m2'].cast(DoubleType()))\\\n",
        "  .withColumn('renovated', dataset['renovated'].cast(BooleanType()))\\\n",
        "  .withColumn('nice_view', dataset['nice_view'].cast(BooleanType()))\\\n",
        "  .withColumn('perfect_condition', dataset['perfect_condition'].cast(BooleanType()))\\\n",
        "  .withColumn('real_bathrooms', dataset['real_bathrooms'].cast(IntegerType()))\\\n",
        "  .withColumn('has_lavatory', dataset['has_lavatory'].cast(BooleanType()))\\\n",
        "  .withColumn('single_floor', dataset['single_floor'].cast( BooleanType()))\\\n",
        "  .withColumn('month', dataset['month'].cast(IntegerType()))\\\n",
        "  .withColumn('quartile_zone', dataset['quartile_zone'].cast(IntegerType()))\\\n",
        "  .withColumn('price', dataset['price'].cast(LongType()))\\\n",
        "  .printSchema()"
      ],
      "metadata": {
        "id": "zqXQV5ZizDVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset\\\n",
        "  .withColumn('grade', dataset['grade'].cast(IntegerType()))\\\n",
        "  .withColumn('bedrooms', dataset['bedrooms'].cast(IntegerType()))\\\n",
        "  .withColumn('has_basement', dataset['has_basement'].cast(BooleanType()))\\\n",
        "  .withColumn('living_in_m2', dataset['living_in_m2'].cast(DoubleType()))\\\n",
        "  .withColumn('renovated', dataset['renovated'].cast(BooleanType()))\\\n",
        "  .withColumn('nice_view', dataset['nice_view'].cast(BooleanType()))\\\n",
        "  .withColumn('perfect_condition', dataset['perfect_condition'].cast(BooleanType()))\\\n",
        "  .withColumn('real_bathrooms', dataset['real_bathrooms'].cast(IntegerType()))\\\n",
        "  .withColumn('has_lavatory', dataset['has_lavatory'].cast(BooleanType()))\\\n",
        "  .withColumn('single_floor', dataset['single_floor'].cast( BooleanType()))\\\n",
        "  .withColumn('month', dataset['month'].cast(IntegerType()))\\\n",
        "  .withColumn('quartile_zone', dataset['quartile_zone'].cast(IntegerType()))\\\n",
        "  .withColumn('price', dataset['price'].cast(LongType()))"
      ],
      "metadata": {
        "id": "7TqywcIxzo9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.show()"
      ],
      "metadata": {
        "id": "NpmdEfEpgh-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('bedrooms')\\\n",
        ".groupby('bedrooms')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "yWXYlXkDNnt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('grade')\\\n",
        ".groupby('grade')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "Wy_6OBsgrIXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('has_basement')\\\n",
        ".groupby('has_basement')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "qf6kjdKO4X9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('renovated')\\\n",
        ".groupby('renovated')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "tU0YM9BJRBcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('nice_view')\\\n",
        ".groupby('nice_view')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "4FN4jqfvSinD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('perfect_condition')\\\n",
        ".groupby('perfect_condition')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "ccxdH-5-hvCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('real_bathrooms')\\\n",
        ".groupby('real_bathrooms')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "OBkrMIuMPpgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('has_lavatory')\\\n",
        ".groupby('has_lavatory')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "ZHZgDmXEiDJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('month')\\\n",
        ".groupby('month')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "0E4Jpr0XiNEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        ".select('quartile_zone')\\\n",
        ".groupby('quartile_zone')\\\n",
        ".count()\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "JBDwZlhatt9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tratamento para dados faltantes"
      ],
      "metadata": {
        "id": "-GygqdGWjahK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f"
      ],
      "metadata": {
        "id": "QYbCyfSajYHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.show()"
      ],
      "metadata": {
        "id": "zL3Z389Ij2bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contagem de valores faltantes"
      ],
      "metadata": {
        "id": "I3eUmQuckSeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql import types # Import the types module\n",
        "\n",
        "dataset\\\n",
        ".select([f.count(f.when((f.col(c).cast(\"double\").isNull()) | (f.isnan(f.col(c).cast(\"double\"))), True)).alias(c) if dataset.schema[c].dataType in [types.DoubleType(), types.FloatType()]\n",
        "         else f.count(f.when(f.col(c).isNull(), True)).alias(c)\n",
        "         for c in dataset.columns])\\\n",
        ".show()"
      ],
      "metadata": {
        "id": "SHgCMMbUl5ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regressão Linear"
      ],
      "metadata": {
        "id": "jJkd-XAZDg2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variáveis Dummy"
      ],
      "metadata": {
        "id": "l8LmIgC_FYP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparando dados para regressão"
      ],
      "metadata": {
        "id": "0BsCH2xtMvUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.show()"
      ],
      "metadata": {
        "id": "Ks0zkVpgErmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear coluna bedrooms pra 1 quarto, 2 quartos e 3 quartos\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Criar uma nova coluna com base nos valores de 'bedrooms'\n",
        "dataset = dataset.withColumn(\n",
        "    \"bedrooms_category\",\n",
        "     when(dataset[\"bedrooms\"] == 1, \"1 bedroom\")\n",
        "    .when(dataset[\"bedrooms\"] == 2, \"2 bedrooms\")\n",
        "    .when(dataset[\"bedrooms\"] == 3, \"3 bedrooms\")\n",
        "    .otherwise(\"Outros\")  # Define um valor padrão para outros números de bedrooms\n",
        ")"
      ],
      "metadata": {
        "id": "mMrTr7DJJz-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"bedrooms\")"
      ],
      "metadata": {
        "id": "hGpIFA63fbV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        "  .groupBy(\"ID\")\\\n",
        "  .pivot(\"bedrooms_category\")\\\n",
        "  .agg(f.lit(1))\\\n",
        "  .na\\\n",
        "  .fill(0)\\\n",
        "  .show()"
      ],
      "metadata": {
        "id": "kQR7vPZAKHhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bedrooms_category = dataset\\\n",
        "                    .groupBy(\"ID\")\\\n",
        "                    .pivot(\"bedrooms_category\")\\\n",
        "                    .agg(f.lit(1))\\\n",
        "                    .na\\\n",
        "                    .fill(0)"
      ],
      "metadata": {
        "id": "em5-wYRJAIIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"bedrooms_category\")"
      ],
      "metadata": {
        "id": "2DDWmqCFb7HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear coluna grade pra 1 grade, 2 grades e 3 grades\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Criar uma nova coluna com base nos valores de 'bedrooms'\n",
        "dataset = dataset.withColumn(\n",
        "    \"grades_category\",\n",
        "     when(dataset[\"grade\"] == 1, \"1 grade\")\n",
        "    .when(dataset[\"grade\"] == 2, \"2 grades\")\n",
        "    .when(dataset[\"grade\"] == 3, \"3 grades\")\n",
        "    .when(dataset[\"grade\"] == 4, \"4 grades\")\n",
        "    .when(dataset[\"grade\"] == 5, \"5 grades\")\n",
        "\n",
        "    .otherwise(\"Outros\")  # Define um valor padrão para outros números de grades\n",
        ")"
      ],
      "metadata": {
        "id": "CbdczcIrhDsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"grade\")"
      ],
      "metadata": {
        "id": "GttP-FKdcKWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        "  .groupBy(\"ID\")\\\n",
        "  .pivot(\"grades_category\")\\\n",
        "  .agg(f.lit(1))\\\n",
        "  .na\\\n",
        "  .fill(0)\\\n",
        "  .show()"
      ],
      "metadata": {
        "id": "-CERLfNX_vib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grade_category = dataset\\\n",
        "                  .groupBy(\"ID\")\\\n",
        "                  .pivot(\"grades_category\")\\\n",
        "                  .agg(f.lit(1))\\\n",
        "                  .na\\\n",
        "                  .fill(0)\n"
      ],
      "metadata": {
        "id": "HHOwuD7ACfl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"grades_category\")\n"
      ],
      "metadata": {
        "id": "mgY4kC7wecKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "dataset = dataset.withColumn(\n",
        "    \"has_basement\",\n",
        "    when(dataset[\"has_basement\"], 1).otherwise(0)\n",
        ")"
      ],
      "metadata": {
        "id": "SD7J18RTTQ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.withColumn(\n",
        "    \"renovated\",\n",
        "    when(dataset[\"renovated\"], 1).otherwise(0)\n",
        ")"
      ],
      "metadata": {
        "id": "6j9C_1GZWwRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.withColumn(\n",
        "    \"nice_view\",\n",
        "    when(dataset[\"nice_view\"], 1).otherwise(0)\n",
        ")"
      ],
      "metadata": {
        "id": "03dVwfxVYXay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.withColumn(\n",
        "    \"perfect_condition\",\n",
        "    when(dataset[\"perfect_condition\"], 1).otherwise(0)\n",
        ")"
      ],
      "metadata": {
        "id": "JBouRqglZH1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear coluna real_bedrooms pra 1 real bathroom, 2 real bathrooms e 3 real bathrooms\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Criar uma nova coluna com base nos valores de 'real_bedrooms'\n",
        "dataset = dataset.withColumn(\n",
        "    \"real_bathrooms_category\",\n",
        "     when(dataset[\"real_bathrooms\"] == 1, \"1 real bathroom\")\n",
        "    .when(dataset[\"real_bathrooms\"] == 2, \"2 real bathrooms\")\n",
        "    .when(dataset[\"real_bathrooms\"] == 3, \"3 real bathrooms\")\n",
        "\n",
        "    .otherwise(\"Outros\")  # Define um valor padrão para outros números de grades\n",
        ")"
      ],
      "metadata": {
        "id": "mBSDwBEnIr5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"real_bathrooms\")"
      ],
      "metadata": {
        "id": "CeqXH8uzh5iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        "  .groupBy(\"ID\")\\\n",
        "  .pivot(\"real_bathrooms_category\")\\\n",
        "  .agg(f.lit(1))\\\n",
        "  .na\\\n",
        "  .fill(0)\\\n",
        "  .show()"
      ],
      "metadata": {
        "id": "4YTUAgpjHLsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_bathrooms_category = dataset\\\n",
        "                          .groupBy(\"ID\")\\\n",
        "                          .pivot(\"real_bathrooms_category\")\\\n",
        "                          .agg(f.lit(1))\\\n",
        "                          .na\\\n",
        "                          .fill(0)"
      ],
      "metadata": {
        "id": "3Mg2Hpe5En2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"real_bathrooms_category\")"
      ],
      "metadata": {
        "id": "-hwfyHi3dGr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.withColumn(\n",
        "    \"single_floor\",\n",
        "    when(dataset[\"single_floor\"], 1).otherwise(0)\n",
        ")"
      ],
      "metadata": {
        "id": "Dtag3P7xZfCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.withColumn(\n",
        "    \"has_lavatory\",\n",
        "    when(dataset[\"has_lavatory\"], 1).otherwise(0)\n",
        ")"
      ],
      "metadata": {
        "id": "jF0b2mgraJwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear coluna month pra Janeiro, Fevereiro, Março, Abril, Maio, Junho,\n",
        "# Julho, Agosto, Setembro, Outubro, Novembro e Dezembro.\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Criar uma nova coluna com base nos valores de 'real_bedrooms'\n",
        "dataset = dataset.withColumn(\n",
        "    \"month_category\",\n",
        "     when(dataset[\"month\"] == 1, \"Janeiro\")\n",
        "    .when(dataset[\"month\"] == 2, \"Fevereiro\")\n",
        "    .when(dataset[\"month\"] == 3, \"Março\")\n",
        "    .when(dataset[\"month\"] == 4, \"Abril\")\n",
        "    .when(dataset[\"month\"] == 5, \"Maio\")\n",
        "    .when(dataset[\"month\"] == 6, \"Junho\")\n",
        "    .when(dataset[\"month\"] == 7, \"Julho\")\n",
        "    .when(dataset[\"month\"] == 8, \"Agosto\")\n",
        "    .when(dataset[\"month\"] == 9, \"Setembro\")\n",
        "    .when(dataset[\"month\"] == 10, \"Outubro\")\n",
        "    .when(dataset[\"month\"] == 11, \"Novembro\")\n",
        "    .when(dataset[\"month\"] == 12, \"Dezembro\")\n",
        "\n",
        "    .otherwise(\"Outros\")  # Define um valor padrão para outros números de grades\n",
        ")"
      ],
      "metadata": {
        "id": "PhbhDMELXC9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"month\")"
      ],
      "metadata": {
        "id": "9CiiEM5Dgbuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        "  .groupBy(\"ID\")\\\n",
        "  .pivot(\"month_category\")\\\n",
        "  .agg(f.lit(1))\\\n",
        "  .na\\\n",
        "  .fill(0)\\\n",
        "  .show()"
      ],
      "metadata": {
        "id": "yAtzS-8Ej8vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "month_category = dataset\\\n",
        "                .groupBy(\"ID\")\\\n",
        "                .pivot(\"month_category\")\\\n",
        "                .agg(f.lit(1))\\\n",
        "                .na\\\n",
        "                .fill(0)"
      ],
      "metadata": {
        "id": "iGrpKvscGCry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"month_category\")"
      ],
      "metadata": {
        "id": "BVNAY8-fbVvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear coluna real_bedrooms pra 1 real bathroom, 2 real bathrooms e 3 real bathrooms\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Criar uma nova coluna com base nos valores de 'real_bedrooms'\n",
        "dataset = dataset.withColumn(\n",
        "    \"quartile_zone_category\",\n",
        "     when(dataset[\"quartile_zone\"] == 1, \"1 quartile zone\")\n",
        "    .when(dataset[\"quartile_zone\"] == 2, \"2 quartiles zones\")\n",
        "    .when(dataset[\"quartile_zone\"] == 3, \"3 quartiles zones\")\n",
        "    .when(dataset[\"quartile_zone\"] == 4, \"4 quartiles zones\")\n",
        "\n",
        "    .otherwise(\"Outros\")  # Define um valor padrão para outros números de grades\n",
        ")"
      ],
      "metadata": {
        "id": "t7navVTD4NMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"quartile_zone\")"
      ],
      "metadata": {
        "id": "6rxauZ0dgt1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\\\n",
        "  .groupBy(\"ID\")\\\n",
        "  .pivot(\"quartile_zone_category\")\\\n",
        "  .agg(f.lit(1))\\\n",
        "  .na\\\n",
        "  .fill(0)\\\n",
        "  .show()"
      ],
      "metadata": {
        "id": "LWLJS-mR5RLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quartile_zone_category = dataset\\\n",
        "                        .groupBy(\"ID\")\\\n",
        "                        .pivot(\"quartile_zone_category\")\\\n",
        "                        .agg(f.lit(1))\\\n",
        "                        .na\\\n",
        "                        .fill(0)"
      ],
      "metadata": {
        "id": "nmhiJltxGWNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(\"quartile_zone_category\")"
      ],
      "metadata": {
        "id": "rmeONkIm97at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset\\\n",
        "  .join(bedrooms_category, on = \"ID\", how = \"inner\")\\\n",
        "  .join(grade_category, on = \"ID\", how = \"inner\")\\\n",
        "  .join(real_bathrooms_category, on = \"ID\", how = \"inner\")\\\n",
        "  .join(month_category, on = \"ID\", how = \"inner\")\\\n",
        "  .join(quartile_zone_category, on = \"ID\", how = \"inner\")"
      ],
      "metadata": {
        "id": "NvHa_XGm9Cds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.show()"
      ],
      "metadata": {
        "id": "IHeBPkmLMpYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vetorização dos dados"
      ],
      "metadata": {
        "id": "mj6cqKzE8jSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "lh1pOhCV8mZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.withColumnRenamed(\"price\", \"label\")"
      ],
      "metadata": {
        "id": "AT4DAd-98w8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = ['has_basement',\n",
        "     'living_in_m2',\n",
        "     'renovated',\n",
        "     'nice_view',\n",
        "     'perfect_condition',\n",
        "     'has_lavatory',\n",
        "     'single_floor',\n",
        "     '1 bedroom',\n",
        "     '2 bedrooms',\n",
        "     '3 bedrooms',\n",
        "     '1 grade',\n",
        "     '2 grades',\n",
        "     '3 grades',\n",
        "     '4 grades',\n",
        "     '5 grades',\n",
        "     '1 real bathroom',\n",
        "     '2 real bathrooms',\n",
        "     '3 real bathrooms',\n",
        "     'Janeiro',\n",
        "     'Fevereiro',\n",
        "     'Março',\n",
        "     'Abril',\n",
        "     'Maio',\n",
        "     'Junho',\n",
        "     'Julho',\n",
        "     'Agosto',\n",
        "     'Setembro',\n",
        "     'Outubro',\n",
        "     'Novembro',\n",
        "     'Dezembro',\n",
        "     '1 quartile zone',\n",
        "     '2 quartiles zones',\n",
        "     '3 quartiles zones',\n",
        "     '4 quartiles zones'\n",
        "]"
      ],
      "metadata": {
        "id": "lkW6beVb-wVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols = X, outputCol = \"features\")"
      ],
      "metadata": {
        "id": "0ScCJaXUBPpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_prep = assembler.transform(dataset).select(\"features\", \"label\")"
      ],
      "metadata": {
        "id": "u_l9WXimBfxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_prep.show(10, truncate = False)"
      ],
      "metadata": {
        "id": "tuLijfkXCHmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploração de dados"
      ],
      "metadata": {
        "id": "Qm2-Ljq4ChUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.stat import Correlation\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kQwEMBfyChAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacao = Correlation.corr(dataset_prep, \"features\").collect()"
      ],
      "metadata": {
        "id": "00wb_erAJ5TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacao"
      ],
      "metadata": {
        "id": "DA594sELU6oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacao = Correlation.corr(dataset_prep, \"features\").collect()[0][0]"
      ],
      "metadata": {
        "id": "bni7bCAlU-kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacao"
      ],
      "metadata": {
        "id": "FFYQ2AemVLrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pyspark.ml.linalg import DenseMatrix\n",
        "\n",
        "correlacao_np = correlacao\n",
        "# Converte matriz densa para numpy array\n",
        "correlacao_np = correlacao_np.toArray()\n",
        "correlacao_list = correlacao_np.tolist()  # Converte para lista"
      ],
      "metadata": {
        "id": "2CNcZtgI18Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# # Remodelar a matriz para corresponder ao formato esperado da matriz de correlação\n",
        "num_features = len(X)\n",
        "\n",
        "# Converte matriz densa para numpy array\n",
        "correlacao_np = correlacao.toArray()\n",
        "correlacao_np = correlacao_np.reshape((num_features, num_features))  # Remodelar para 34x34\n",
        "\n",
        "dataframe_correlacao = pd.DataFrame(correlacao_np, columns=X, index=X)"
      ],
      "metadata": {
        "id": "O_pDWqOZ2UJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_correlacao"
      ],
      "metadata": {
        "id": "KWdI_YleZNJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapa de calor"
      ],
      "metadata": {
        "id": "rpZtK8imZXf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "j2gjTWcJZZno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12, 10))\n",
        "paleta = sns.color_palette(\"light:salmon\", as_cmap = True)\n",
        "sns.heatmap(dataframe_correlacao.round(1), annot = True, cmap = paleta)"
      ],
      "metadata": {
        "id": "oiQzJuFaZga1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajuste e Previsão"
      ],
      "metadata": {
        "id": "4_bWdbfl8OI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "wM8iN1Nc8Nrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino, teste = dataset_prep.randomSplit([0.7, 0.3], seed = 101)"
      ],
      "metadata": {
        "id": "4Z1M4sA99ORu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino.count()"
      ],
      "metadata": {
        "id": "_ABqk5kC9lNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste.count()"
      ],
      "metadata": {
        "id": "wZY76K_b9ou6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()"
      ],
      "metadata": {
        "id": "pv8y4VPW9q5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_lr = lr.fit(treino)"
      ],
      "metadata": {
        "id": "30yHXtUy9us3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes_lr_treino = modelo_lr.transform(treino)"
      ],
      "metadata": {
        "id": "NrXbnSws904N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes_lr_treino.show()"
      ],
      "metadata": {
        "id": "UIxP3W9wBIZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas"
      ],
      "metadata": {
        "id": "_HnacElGBU0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resumo_treino = modelo_lr.summary"
      ],
      "metadata": {
        "id": "FZvNYAKcBQsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumo_treino.r2"
      ],
      "metadata": {
        "id": "HkKDZAUXBfsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumo_treino.rootMeanSquaredError"
      ],
      "metadata": {
        "id": "mEHLbLRDGZQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumo_teste = modelo_lr.evaluate(teste)"
      ],
      "metadata": {
        "id": "bydDBlY8GcOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumo_teste.r2"
      ],
      "metadata": {
        "id": "WhJ7n17gGgw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumo_teste.rootMeanSquaredError"
      ],
      "metadata": {
        "id": "6XirCxnjGjs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tabela Resumo Regressão Linear"
      ],
      "metadata": {
        "id": "qi8PQ7lzJcyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Linear Regression\")\n",
        "print(\"=\"*30)\n",
        "print(\"Dados de Treino\")\n",
        "print(\"=\"*30)\n",
        "print(\"R²: %f\" % resumo_treino.r2)\n",
        "print(\"RMSE: %f\" % resumo_treino.rootMeanSquaredError)\n",
        "print(\"\")\n",
        "print(\"=\"*30)\n",
        "print(\"Dados de Teste\")\n",
        "print(\"=\"*30)\n",
        "print(\"R²: %f\" % resumo_teste.r2)\n",
        "print(\"RMSE: %f\" % resumo_teste.rootMeanSquaredError)"
      ],
      "metadata": {
        "id": "qYf1LXSrJcCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prevendo resultados"
      ],
      "metadata": {
        "id": "a-zrp-XvMSvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.show(15)"
      ],
      "metadata": {
        "id": "BaRtbusjLjGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "AmnrDNwqMuvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "novo_imovel = [{\n",
        " 'has_basement':2,\n",
        " 'living_in_m2':103,\n",
        " 'renovated':1,\n",
        " 'nice_view':1,\n",
        " 'perfect_condition':1,\n",
        " 'has_lavatory':1,\n",
        " 'single_floor':1 ,\n",
        " '1 bedroom':0 ,\n",
        " '2 bedrooms':0,\n",
        " '3 bedrooms':1,\n",
        " '1 grade':0,\n",
        " '2 grades':0,\n",
        " '3 grades':1,\n",
        " '4 grades':0,\n",
        " '5 grades':0,\n",
        " '1 real bathroom':1,\n",
        " '2 real bathrooms':0,\n",
        " '3 real bathrooms':0,\n",
        " 'Janeiro':1,\n",
        " 'Fevereiro':0,\n",
        " 'Março':0,\n",
        " 'Abril':0,\n",
        " 'Maio':0,\n",
        " 'Junho':0,\n",
        " 'Julho':0,\n",
        " 'Agosto':0,\n",
        " 'Setembro':0,\n",
        " 'Outubro':0,\n",
        " 'Novembro':0,\n",
        " 'Dezembro':0,\n",
        " '1 quartile zone':0,\n",
        " '2 quartiles zones':0,\n",
        " '3 quartiles zones':1,\n",
        " '4 quartiles zones':0,\n",
        " 'label':0}]"
      ],
      "metadata": {
        "id": "X0_UnybhNpt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meu_imovel = spark.createDataFrame(novo_imovel)"
      ],
      "metadata": {
        "id": "8yG3qZloPI5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meu_imovel.show()"
      ],
      "metadata": {
        "id": "IOIsH6GFPs8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols = X, outputCol = \"features\")"
      ],
      "metadata": {
        "id": "icvDR_C2QHVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meu_lar_vetorizado = assembler.transform(meu_imovel).select(\"features\", \"label\")"
      ],
      "metadata": {
        "id": "8WDeopffQRrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meu_lar_vetorizado.show()"
      ],
      "metadata": {
        "id": "daNBJm4wSPSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prever price do meu_lar_vetorizado\n",
        "\n",
        "previsao = modelo_lr.transform(meu_lar_vetorizado)\n",
        "print(f\"O preço previsto para o imóvel é de: {previsao.select('prediction').collect()[0][0]}\")\n"
      ],
      "metadata": {
        "id": "uG6xymdVWve6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}